{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following code snippet \n",
    "+ combines physiological episodes with relevant RR interval information\n",
    "+ divides each episode's duration into 5-min windows with 1-min sliding window; retains windows with at least 4 or more distinct minutes\n",
    "+ computes various aggregated HRV features from the 5-min windows for each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark Version :3.1.2\n"
     ]
    }
   ],
   "source": [
    "from cerebralcortex import Kernel\n",
    "from datetime import datetime, date, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.types import StructField, StructType, DoubleType, StringType, ArrayType, \\\n",
    "TimestampType, IntegerType, DateType\n",
    "from scipy.stats import iqr\n",
    "import warnings\n",
    "\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "CC = Kernel(\"/home/jupyter/cc3_moods_conf/\", study_name=\"moods\")\n",
    "print('PySpark Version :'+CC.sparkContext.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch, clean and filter episodes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/jupyter/sneupane/MOODS/analysis/papers/CHI/dataframe/final_df.pickle', 'rb') as handle:\n",
    "    final_df = pickle.load(handle)\n",
    "df_users_episodes = final_df\n",
    "df_users_episodes.columns = df_users_episodes.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['stress_id', 'starttime', 'endtime', 'value', 'episode_class', 'deleted',\n",
    "         'state', 'user_generated', 'user_rating', 'location', 'selected', 'created',\n",
    "         'last_updated', 'label', 'stressor', 'version', 'user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uuid_substitutions={\"4e3c01a1-4f61-3329-b843-edd72eaece63\":\"62c32dbd-a32d-3ecd-a9f1-fb9bc40fff66\",\n",
    "                   \"37686d8b-d47b-33e9-99b1-496196e7ada2\":\"ff54abe7-a4dd-3c10-a00d-e9bcc68ee92b\",\n",
    "                   \"68d89413-5a7f-3a3b-9e6c-b22d2699307a\":\"07c8b674-2c13-3a33-a973-cf1cab70d9f9\",\n",
    "                   \"7e0aa5f7-96cd-3a95-a28d-e3ef3684e0e1\":\"71e88740-be67-382a-a21f-78fba469cb13\",\n",
    "                   \"559c51b0-672e-32d9-a1d7-f7b36b5190af\":\"f7400971-a4b7-326a-8120-2e1db7f91cca\",\n",
    "                   \"b9b13911-dda5-38de-bb0d-becd0c9a4c7d\":\"835c291b-ecf4-32da-9a58-67bfe5ecfb7f\",\n",
    "                   \"fd1574fe-3093-3519-949e-15c98b4bc73a\":\"d8404d54-51d1-35fc-9bf7-32aa5942c575\",\n",
    "                   \"336482c0-71cf-39c8-96bb-8aeb7ffa4d3f\":\"b0a58353-edf9-3213-9bd5-808e7ad42bd5\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_quality_issues(pdf, \n",
    "                        uuid_substitutions):\n",
    "    filt = pdf['starttime'] > pdf['endtime']\n",
    "    pdf.loc[filt, 'starttime'], pdf.loc[filt, 'endtime'] = (pdf.loc[filt, 'endtime'], \n",
    "                                                            pdf.loc[filt, 'starttime'])\n",
    "    pdf['user'] = pdf['user'].replace(uuid_substitutions)\n",
    "    return pdf\n",
    "     \n",
    "def tweak_ds_users_episodes(df_users_episodes, \n",
    "                            cols):        \n",
    "    return (df_users_episodes[cols]\n",
    "            .assign(starttime=pd.to_datetime(df_users_episodes['starttime']), \n",
    "                    endtime=pd.to_datetime(df_users_episodes['endtime']),\n",
    "                    eps_dur=((df_users_episodes['endtime'] - df_users_episodes['starttime'])\n",
    "                             .dt.total_seconds() / 60),\n",
    "                    date=df_users_episodes['starttime'].dt.date, \n",
    "                    rated=np.where(df_users_episodes['user_rating'].notnull(), 1, 0))\n",
    "            .sort_values(by=['user', 'endtime'])\n",
    "           )\n",
    "\n",
    "df_users_episodes = data_quality_issues(tweak_ds_users_episodes(df_users_episodes, \n",
    "                                                                cols), \n",
    "                                        uuid_substitutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list(df_users_episodes['user'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract annotated episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26732"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_eps_pdf = (df_users_episodes.loc[df_users_episodes['user']\n",
    "                                       .isin(users)]\n",
    "                 .loc[lambda df: df['rated'] == 1])\n",
    "len(check_eps_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------------------+-------------------+\n",
      "|                user|stress_id|          starttime|            endtime|\n",
      "+--------------------+---------+-------------------+-------------------+\n",
      "|00222a15-7274-34b...|   162009|2022-09-20 14:56:18|2022-09-20 15:05:28|\n",
      "|00222a15-7274-34b...|   162201|2022-09-20 15:41:22|2022-09-20 16:19:26|\n",
      "|00222a15-7274-34b...|   162202|2022-09-20 16:19:26|2022-09-20 16:29:27|\n",
      "|00222a15-7274-34b...|   162210|2022-09-20 17:55:30|2022-09-20 18:08:30|\n",
      "|00222a15-7274-34b...|   162539|2022-09-21 14:18:10|2022-09-21 14:31:11|\n",
      "+--------------------+---------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_eps_pdf = check_eps_pdf[['user', 'stress_id', 'starttime', 'endtime']]\n",
    "                                                                       \n",
    "check_eps_sdf = CC.sparkSession.createDataFrame(check_eps_pdf)\n",
    "check_eps_sdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract RR-interval data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rr_intervals(stream_name, CC):\n",
    "    ds = CC.get_stream(stream_name, version=\"all\")\n",
    "    return ds\n",
    "\n",
    "CC = Kernel(\"/home/jupyter/cc3_moods_conf/\", study_name=\"moods\")\n",
    "stream_name = 'rr_interval--org.md2k.watch--fossil_watch_sport'\n",
    "ds_rr = (get_rr_intervals(stream_name, CC)\n",
    "         .data\n",
    "         .orderBy(['user', 'localtime'])\n",
    "         .withColumn('date', F.col(\"localtime\").cast('date'))\n",
    "         .withColumn('HR', 60000/F.col('interval')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_rr.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter RR intervals of users whose annoated episodes were extracted in the previous step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_rr_sdf = ds_rr.filter(ds_rr['user'].isin(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_rr_sdf.select(['user']).distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge episodes with relevant RR information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "join_eps_rr_sdf = (check_rr_sdf.join(check_eps_sdf)\n",
    "                   .filter((check_rr_sdf['user'] == check_eps_sdf['user']) &\n",
    "                           (check_rr_sdf['localtime'] >= check_eps_sdf['starttime']) &\n",
    "                           (check_rr_sdf['localtime'] <= check_eps_sdf['endtime']))\n",
    "                   .drop(check_eps_sdf['user']).orderBy(['stress_id', 'localtime']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join_eps_rr_sdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 5-min windows with 1-min sliding window; keep windows with at least 4 or more distinct minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "return_schema = StructType([StructField(\"user\", StringType()),\n",
    "                            StructField(\"stress_id\", IntegerType()),\n",
    "                            StructField(\"localtime_st\", TimestampType()),\n",
    "                            StructField(\"localtime_et\", TimestampType()),\n",
    "                            StructField(\"date\", DateType()),\n",
    "                            StructField(\"interval_list\", ArrayType(DoubleType())),\n",
    "                            StructField(\"rank\", IntegerType()),\n",
    "                            StructField(\"distinct_min_count\", IntegerType())                                        \n",
    "                           ])\n",
    "                                \n",
    "@pandas_udf(return_schema, PandasUDFType.GROUPED_MAP)\n",
    "def create_window(eps_df):\n",
    "    window_dur = 300\n",
    "    sliding_dur = 60\n",
    "    eps_df = eps_df.sort_values(by=['localtime'])\n",
    "    if (eps_df['endtime'].iloc[0] - eps_df['starttime'].iloc[0]).total_seconds() < window_dur:\n",
    "        return pd.DataFrame(columns=[f.name for f in return_schema])\n",
    "\n",
    "    rank = 0        \n",
    "    win_st = eps_df['starttime'].iloc[0]\n",
    "    win_et = win_st + timedelta(seconds=window_dur)\n",
    "    windows = []\n",
    "    while win_et <= eps_df['endtime'].iloc[-1]:\n",
    "        lt_list = eps_df.loc[(eps_df['localtime'] >= win_st) \n",
    "                             & (eps_df['localtime'] <= win_et), 'localtime'].to_list()\n",
    "\n",
    "        unique_ts = {pd.to_datetime(ts).minute for ts in lt_list}\n",
    "        if len(unique_ts) >= 4:\n",
    "            rr_list = eps_df.loc[(eps_df['localtime'] >= win_st) \n",
    "                                 & (eps_df['localtime'] <= win_et), 'interval'].to_list()\n",
    "\n",
    "            windows.append([eps_df['user'].iloc[0], eps_df['stress_id'].iloc[0], \n",
    "                            win_st, win_et, \n",
    "                            eps_df['date'].iloc[0], \n",
    "                            rr_list, rank, len(unique_ts)])\n",
    "            rank += 1\n",
    "        win_st = win_st + timedelta(seconds=sliding_dur)\n",
    "        win_et = win_st + timedelta(seconds=window_dur)\n",
    "        \n",
    "    return pd.DataFrame(windows, columns=[f.name for f in return_schema])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_5_min_window = join_eps_rr_sdf.groupBy(['user', 'stress_id']).apply(create_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_5_min_window.orderBy('stress_id').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute aggregated HRV features from the 5-min windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_schema = StructType([StructField(\"user\", StringType()),\n",
    "                            StructField(\"stress_id\", IntegerType()),\n",
    "                            StructField('hrv_mean', DoubleType()),\n",
    "                            StructField('hrv_median', DoubleType()),\n",
    "                            StructField('hrv_iqr', DoubleType()),\n",
    "                            StructField('hrv_80P', DoubleType()),\n",
    "                            StructField('hrv_20P', DoubleType()),\n",
    "                            StructField('SDANN', DoubleType()),\n",
    "                            StructField('RMSSD', DoubleType()),\n",
    "                           ])\n",
    "                                \n",
    "@pandas_udf(return_schema, PandasUDFType.GROUPED_MAP)\n",
    "def window_features(user_data):\n",
    "    result_df = pd.DataFrame(columns=[c.name for c in return_schema])    \n",
    "    group_dfs = user_data.groupby('stress_id')\n",
    "    for stress_id, df in group_dfs:\n",
    "        df['avg_IBI'] = df['interval_list'].apply(lambda x : np.mean(x))\n",
    "        idx = len(result_df)\n",
    "        result_df.loc[idx, \"user\"] = df['user'].iloc[0]\n",
    "        result_df.loc[idx, \"stress_id\"] = stress_id\n",
    "        result_df.loc[idx, 'hrv_mean'] = np.mean(df['avg_IBI'])\n",
    "        result_df.loc[idx, 'hrv_median'] = np.median(df['avg_IBI'])\n",
    "        result_df.loc[idx, 'hrv_iqr'] = iqr(df['avg_IBI'])        \n",
    "        result_df.loc[idx, 'hrv_80P'] = np.percentile(df['avg_IBI'], 80)\n",
    "        result_df.loc[idx, 'hrv_20P'] = np.percentile(df['avg_IBI'], 20)\n",
    "        result_df.loc[idx, 'SDANN'] = np.std(df['avg_IBI'])\n",
    "        result_df.loc[idx, 'RMSSD'] = np.sqrt(np.mean(np.square(np.diff(df['avg_IBI']))))\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sdf = (valid_5_min_window\n",
    "                .orderBy([\"stress_id\", \"localtime_st\"])\n",
    "                .groupBy('user').apply(window_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-----------------+------------------+-----------------+-----------------+------------------+------------------+\n",
      "|stress_id|         hrv_mean|       hrv_median|           hrv_iqr|          hrv_80P|          hrv_20P|             SDANN|             RMSSD|\n",
      "+---------+-----------------+-----------------+------------------+-----------------+-----------------+------------------+------------------+\n",
      "|   189816|788.6829134275097|795.3780864197531| 33.43076333277975|808.6480922135969|767.7766497082149|21.455545589884377|  9.47965117349114|\n",
      "|   189818|731.2042933311726|729.3590504451039| 25.88859530004413|744.2334090909092|715.5899586758094|20.003336898839038|17.489572353460037|\n",
      "|   189821|746.7963322994786|740.0636604774536| 4.838740509396416|750.0378333587737|738.1612560488113|14.714896100462914|16.647170185749015|\n",
      "|   189824|832.0487012987013|832.0487012987013|12.656655844155807|839.6426948051948| 824.454707792208|12.656655844155807|25.313311688311614|\n",
      "|   189826|763.0314279135781|767.4563106796116|20.464802579833304| 780.358430359551|748.2903908389346|19.516771288050577|12.239596588010672|\n",
      "+---------+-----------------+-----------------+------------------+-----------------+-----------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_sdf.select(['stress_id', 'hrv_mean', 'hrv_median', \n",
    "                     'hrv_iqr', 'hrv_80P', 'hrv_20P', 'SDANN', 'RMSSD']).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize features individual wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(return_schema, PandasUDFType.GROUPED_MAP)\n",
    "def normalize_window_features(user_feature_data):\n",
    "    for col in user_feature_data.columns:\n",
    "        if col in [\"user\", \"stress_id\"]:continue\n",
    "        user_feature_data[col] = ((user_feature_data[col] - user_feature_data[col].mean()) \n",
    "                                  / user_feature_data[col].std(ddof=0))\n",
    "    return user_feature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features_sdf = features_sdf.groupBy('user').apply(normalize_window_features)\n",
    "normalized_features_pdf = normalized_features_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stress_id</th>\n",
       "      <th>hrv_mean</th>\n",
       "      <th>hrv_median</th>\n",
       "      <th>hrv_iqr</th>\n",
       "      <th>hrv_80P</th>\n",
       "      <th>hrv_20P</th>\n",
       "      <th>SDANN</th>\n",
       "      <th>RMSSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>189816</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.107</td>\n",
       "      <td>0.873</td>\n",
       "      <td>1.208</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.754</td>\n",
       "      <td>-0.582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189818</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>0.461</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>-0.401</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189821</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-0.689</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189824</td>\n",
       "      <td>1.955</td>\n",
       "      <td>1.900</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>1.914</td>\n",
       "      <td>1.866</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>1.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189826</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.579</td>\n",
       "      <td>-0.267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stress_id  hrv_mean  hrv_median  hrv_iqr  hrv_80P  hrv_20P  SDANN  RMSSD\n",
       "0     189816     0.980       1.107    0.873    1.208    0.686  0.754 -0.582\n",
       "1     189818    -0.312      -0.320    0.461   -0.259   -0.401  0.623  0.333\n",
       "2     189821     0.039      -0.088   -0.689   -0.127    0.069  0.146  0.237\n",
       "3     189824     1.955       1.900   -0.262    1.914    1.866 -0.039  1.226\n",
       "4     189826     0.404       0.504    0.165    0.564    0.280  0.579 -0.267"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_features_pdf[['stress_id', 'hrv_mean', 'hrv_median', \n",
    "                     'hrv_iqr', 'hrv_80P', 'hrv_20P', 'SDANN', 'RMSSD']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "High Performance CC3.3",
   "language": "python",
   "name": "cc33_high_performance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
