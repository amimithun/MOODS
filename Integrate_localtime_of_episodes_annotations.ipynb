{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cerebralcortex import Kernel\n",
    "import pyspark.sql.functions as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def episodes_with_last_updated_in_localtime():\n",
    "    def tweak_sdf(sdf, *duplicate_cols):\n",
    "        \"\"\"\n",
    "        Some participants mistakenly registered twice using two different email ids, producing two unique\n",
    "        user ids for the same user. To ensure data integrity, all user ids are replaced by the first id.\n",
    "        Duplicate datapoints are also removed.\n",
    "        \n",
    "        Args:\n",
    "            sdf (pyspark.DataFrame) : A stress likelihood/episode dataframe\n",
    "            *duplicate_cols : A list of two columns used to sort and remove duplicates from the sdf\n",
    "        Returns:\n",
    "            sdf (pyspark.DataFrame) : Modified dataframe\n",
    "        \"\"\"        \n",
    "        sdf = (sdf.withColumn(\"user_id\", F.when(F.col('user') == \"4e3c01a1-4f61-3329-b843-edd72eaece63\",\n",
    "                                                \"62c32dbd-a32d-3ecd-a9f1-fb9bc40fff66\")\n",
    "                                        .when(F.col('user') == \"37686d8b-d47b-33e9-99b1-496196e7ada2\",\n",
    "                                              \"ff54abe7-a4dd-3c10-a00d-e9bcc68ee92b\")\n",
    "                                        .when(F.col('user') == \"68d89413-5a7f-3a3b-9e6c-b22d2699307a\",\n",
    "                                              \"07c8b674-2c13-3a33-a973-cf1cab70d9f9\")\n",
    "                                        .when(F.col('user') == \"7e0aa5f7-96cd-3a95-a28d-e3ef3684e0e1\",\n",
    "                                              \"71e88740-be67-382a-a21f-78fba469cb13\")\n",
    "                                        .when(F.col('user') == \"559c51b0-672e-32d9-a1d7-f7b36b5190af\",\n",
    "                                              \"f7400971-a4b7-326a-8120-2e1db7f91cca\")\n",
    "                                        .when(F.col('user') == \"b9b13911-dda5-38de-bb0d-becd0c9a4c7d\",\n",
    "                                              \"835c291b-ecf4-32da-9a58-67bfe5ecfb7f\")\n",
    "                                        .when(F.col('user') == \"fd1574fe-3093-3519-949e-15c98b4bc73a\",\n",
    "                                              \"d8404d54-51d1-35fc-9bf7-32aa5942c575\")\n",
    "                                        .when(F.col('user') == \"336482c0-71cf-39c8-96bb-8aeb7ffa4d3f\",\n",
    "                                              \"b0a58353-edf9-3213-9bd5-808e7ad42bd5\")\n",
    "                                        .otherwise(F.col('user')))\n",
    "                        .drop('user')\n",
    "                        .withColumnRenamed('user_id', 'user')\n",
    "                        .orderBy([duplicate_cols[0], duplicate_cols[1]])\n",
    "                        .dropDuplicates([duplicate_cols[0], duplicate_cols[1]]))\n",
    "\n",
    "        return sdf\n",
    "\n",
    "    def get_stress_likelihoods(stream_name, CC):\n",
    "        \"\"\"\n",
    "        End of DST was not reflected in the timestamps of the likelihood datastream for app versions < 32.\n",
    "        This method handles that error.\n",
    "    \n",
    "        Args:\n",
    "            stream_name : name of the stream\n",
    "            CC : cerebral cortext boject\n",
    "        Returns:\n",
    "            sdf (pyspark.DataFrame) : End of DST reflected dataframe\n",
    "        \"\"\"        \n",
    "        sdf = (CC.get_stream(stream_name=stream_name, \n",
    "                            version='all')\n",
    "              .withColumn(\"diff_in_seconds\", F.col('endtime')/1000000 \n",
    "                          - F.col('timestamp').cast('long'))\n",
    "              .withColumn(\"localtime_et\", F.to_timestamp(F.col('localtime').cast('long') \n",
    "                                                         + F.col(\"diff_in_seconds\")))\n",
    "              .withColumnRenamed(\"localtime\", \"localtime_st\")\n",
    "              .withColumnRenamed(\"timestamp\", \"UTC_st\")\n",
    "              .withColumn(\"localtime_st_dl\", F.when((F.col('localtime_st') >= \n",
    "                                                     F.lit(\"2021-11-07 02:00:00\")) \n",
    "                                                    & (F.col('version') < 32), \n",
    "                                                    F.to_timestamp(F.col('localtime_st').cast('long') \n",
    "                                                                   - 3600))\n",
    "                          .otherwise(F.col('localtime_st')))\n",
    "              .withColumn(\"localtime_et_dl\", F.when((F.col('localtime_et') >= \n",
    "                                                     F.lit(\"2021-11-07 02:00:00\")) \n",
    "                                                    & (F.col('version') < 32), \n",
    "                                                    F.to_timestamp(F.col('localtime_et').cast('long') \n",
    "                                                                   - 3600))\n",
    "                          .otherwise(F.col('localtime_et')))\n",
    "              .drop('localtime_st', 'localtime_et', 'endtime', \"diff_in_seconds\")\n",
    "              .withColumnRenamed(\"localtime_st_dl\", \"localtime_st\")\n",
    "              .withColumnRenamed(\"localtime_et_dl\", \"localtime_et\"))\n",
    "\n",
    "        return sdf\n",
    "\n",
    "    \n",
    "    def localtime_of_annotations(episode_sdf, likelihood_sdf):\n",
    "        stress_id_last_updated_lt = (episode_sdf.select(['user', 'stress_id', 'starttime', \n",
    "                                                         'endtime', 'last_updated'])._data\n",
    "                                     .join(likelihood_sdf._data)\n",
    "                                     .filter((episode_sdf['user'] == likelihood_sdf['user']) & \n",
    "                                             (likelihood_sdf['localtime_st'] >= \n",
    "                                              F.to_timestamp(episode_sdf['starttime'].cast('long') - 60)) & \n",
    "                                             (likelihood_sdf['localtime_et'] \n",
    "                                              <= F.to_timestamp(episode_sdf['endtime'].cast('long') + 60)))\n",
    "                                     .groupBy('stress_id')\n",
    "                                     .agg(F.min('UTC_st').alias('UTC_st'), \n",
    "                                          F.min('localtime_st').alias('localtime_st'), \n",
    "                                          F.min('last_updated').alias('last_updated'))\n",
    "                                     .withColumn('time_diff_secs', F.when(F.col('UTC_st') > F.col('localtime_st'), \n",
    "                                                                          F.col('UTC_st').cast('long') - \n",
    "                                                                          F.col('localtime_st').cast('long'))\n",
    "                                                                          .otherwise(F.col('localtime_st').cast('long') - \n",
    "                                                                                     F.col('UTC_st').cast('long')))\n",
    "                                     .withColumn(\"last_updated_lt\", F.to_timestamp(F.col('last_updated').cast('long') \n",
    "                                                                                   - F.col('time_diff_secs')))\n",
    "                                     .select('stress_id', \"last_updated_lt\"))\n",
    "\n",
    "        return episode_sdf._data.join(stress_id_last_updated_lt, on='stress_id', how='inner')\n",
    "    \n",
    "    CC = Kernel(\"/home/jupyter/cc3_moods_conf/\", study_name=\"moods\")\n",
    "    episode_sdf = CC.get_stream('org.md2k.moods.episodes', version=\"all\")                         \n",
    "    episode_sdf = tweak_sdf(episode_sdf, 'user', 'endtime')\n",
    "    likelihood_sdf = get_stress_likelihoods('probability--org.md2k.watch--fossil_watch_sport', CC)\n",
    "    likelihood_sdf = tweak_sdf(likelihood_sdf, 'user', 'localtime_st')\n",
    "    episode_sdf = localtime_of_annotations(episode_sdf, likelihood_sdf)\n",
    "    return episode_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "episode_sdf = episodes_with_last_updated_in_localtime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------------------+-------------------+-------------------+-------------------+\n",
      "|                user|stress_id|          starttime|            endtime|       last_updated|    last_updated_lt|\n",
      "+--------------------+---------+-------------------+-------------------+-------------------+-------------------+\n",
      "|af5f95f0-09cc-3a0...|    98166|2022-05-05 12:15:17|2022-05-05 12:33:17|2022-05-07 01:38:42|2022-05-06 20:38:42|\n",
      "|af5f95f0-09cc-3a0...|    98171|2022-05-05 14:01:17|2022-05-05 14:04:17|2022-05-05 22:45:18|2022-05-05 17:45:18|\n",
      "|af5f95f0-09cc-3a0...|    98173|2022-05-05 14:16:17|2022-05-05 14:23:18|2022-05-05 22:45:18|2022-05-05 17:45:18|\n",
      "|af5f95f0-09cc-3a0...|    98182|2022-05-05 15:46:18|2022-05-05 15:51:42|2022-05-05 22:45:18|2022-05-05 17:45:18|\n",
      "|af5f95f0-09cc-3a0...|    98169|2022-05-05 12:53:17|2022-05-05 13:35:17|2022-05-05 22:45:18|2022-05-05 17:45:18|\n",
      "+--------------------+---------+-------------------+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(episode_sdf.filter((F.col('user') == 'af5f95f0-09cc-3a0a-b283-1a0ae724e43c') & \n",
    "                    (F.col('starttime') >= F.lit(\"2022-05-05 12:00:00\")) & \n",
    "                    (F.col('starttime') <= F.lit(\"2022-05-06 12:00:00\")))\n",
    " .select(['user', 'stress_id', 'starttime', 'endtime', \n",
    "          'last_updated', \"last_updated_lt\"])\n",
    " .show(5))                                                                                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CC3.3",
   "language": "python",
   "name": "cc33"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
